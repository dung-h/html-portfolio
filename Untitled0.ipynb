{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGxcWPsVJVwT7DHiZJBKyS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dung-h/html-portfolio/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjGL7fSyW4ow",
        "outputId": "53c0aee1-021f-4330-b019-38bfa902e5d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum element is : 0\n",
            "The time required : 0.003392\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "#include <cstdio>\n",
        "#include <iostream>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void maxi(int* a, int* b, int n)\n",
        "{\n",
        "    int block = 256 * blockIdx.x;\n",
        "    int max = 0;\n",
        "\n",
        "    for (int i = block; i < min(256 + block, n); i++) {\n",
        "\n",
        "        if (max < a[i]) {\n",
        "            max = a[i];\n",
        "        }\n",
        "    }\n",
        "    b[blockIdx.x] = max;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\n",
        "    int n;\n",
        "    n = 3 >> 2;\n",
        "    int a[n];\n",
        "\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        a[i] = rand() % n;\n",
        "        cout << a[i] << \"\\t\";\n",
        "    }\n",
        "\n",
        "    cudaEvent_t start, end;\n",
        "    int *ad, *bd;\n",
        "    int size = n * sizeof(int);\n",
        "    cudaMalloc(&ad, size);\n",
        "    cudaMemcpy(ad, a, size, cudaMemcpyHostToDevice);\n",
        "    int grids = ceil(n * 1.0f / 256.0f);\n",
        "    cudaMalloc(&bd, grids * sizeof(int));\n",
        "\n",
        "    dim3 grid(grids, 1);\n",
        "    dim3 block(1, 1);\n",
        "\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&end);\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    while (n > 1) {\n",
        "        maxi<<<grids, block>>>(ad, bd, n);\n",
        "        n = ceil(n * 1.0f / 256.0f);\n",
        "        cudaMemcpy(ad, bd, n * sizeof(int), cudaMemcpyDeviceToDevice);\n",
        "    }\n",
        "\n",
        "    cudaEventRecord(end);\n",
        "    cudaEventSynchronize(end);\n",
        "\n",
        "    float time = 0;\n",
        "    cudaEventElapsedTime(&time, start, end);\n",
        "\n",
        "    int ans[2];\n",
        "    cudaMemcpy(ans, ad, 4, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cout << \"The maximum element is : \" << ans[0] << endl;\n",
        "\n",
        "    cout << \"The time required : \";\n",
        "    cout << time << endl;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import flax.linen as nn\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "class FourierTransformLayer(nn.Module):\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    return jax.vmap(jnp.fft.fftn)(x).real\n",
        "\n",
        "class FeedForwardLayer(nn.Module):\n",
        "  d_ff: int\n",
        "  dropout_rate: float\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x, deterministic):\n",
        "    x = nn.Dense(self.d_ff,\n",
        "                 kernel_init=nn.initializers.normal(2e-2),\n",
        "                 bias_init=nn.initializers.normal(2e-2),\n",
        "                 name=\"intermediate\")(x)\n",
        "    x = nn.gelu(x)\n",
        "    x = nn.Dense(x.shape[-1],\n",
        "                 kernel_init=nn.initializers.normal(2e-2),\n",
        "                 name=\"output\")(x)\n",
        "    return nn.Dropout(self.dropout_rate)(x, deterministic)\n",
        "\n",
        "class FNetEncoderBlock(nn.Module):\n",
        "  fourier_layer: FourierTransformLayer\n",
        "  ff_layer: FeedForwardLayer\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x, deterministic):\n",
        "    mixing_output = self.fourier_layer(x)\n",
        "    x = nn.LayerNorm(1e-12, name=\"mixing_layer_norm\")(x + mixing_output)\n",
        "    feed_forward_output = self.ff_layer(x, deterministic)\n",
        "    return nn.LayerNorm(1e-12, name=\"output_layer_norm\")(x + feed_forward_output)\n",
        "class FNetEncoder(nn.Module):\n",
        "  num_layers: int\n",
        "  d_model: int\n",
        "  d_ff: int\n",
        "  dropout_rate: float\n",
        "\n",
        "  def setup(self):\n",
        "    encoder_blocks = []\n",
        "    for layer in range(self.num_layers):\n",
        "      encoder_blocks.append(FNetEncoderBlock(FourierTransformLayer(), FeedForwardLayer(self.d_ff, self.dropout_rate), name=f'encoder_{layer}'))\n",
        "    self.encoder_blocks = encoder_blocks\n",
        "    self.pooler = nn.Dense(\n",
        "      self.d_model,\n",
        "      kernel_init=nn.initializers.normal(2e-2),\n",
        "      name='pooler')\n",
        "\n",
        "  def call(self, x, deterministic):\n",
        "    for encoder_block in self.encoder_blocks:\n",
        "      x = encoder_block(x, deterministic)\n",
        "    pooled_output = self.pooler(x[:, 0])\n",
        "    pooled_output = jnp.tanh(pooled_output)\n",
        "    return x, pooled_output"
      ],
      "metadata": {
        "id": "uETOtzWbKqr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "// function to add the elements of two arrays\n",
        "void add(int n, float *x, float *y)\n",
        "{\n",
        "  for (int i = 0; i < n; i++)\n",
        "      y[i] = x[i] + y[i];\n",
        "}\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  int N = 1<<20;\n",
        "\n",
        "  float *x = new float[N];\n",
        "  float *y = new float[N];\n",
        "\n",
        "  // initialize x and y arrays on the host\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    x[i] = 1.0;\n",
        "    y[i] = 2.0;\n",
        "  }\n",
        "\n",
        "  // Run kernel on 1M elements on the CPU\n",
        "  add(N, x, y);\n",
        "\n",
        "  // Check for errors (all values should be 3.0f)\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < N; i++)\n",
        "    maxError = fmax(maxError, fabs(y[i]-3.0f));\n",
        "  std::cout << \"Max error: \" << maxError << std::endl;\n",
        "\n",
        "  // Free memory\n",
        "  delete [] x;\n",
        "  delete [] y;\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "hR1ajcoHEQlZ",
        "outputId": "be7de831-1956-429f-8326-78ba9924991d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid decimal literal (<ipython-input-3-54f74cfc00ef>, line 24)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-54f74cfc00ef>\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    // Run kernel on 1M elements on the CPU\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import flax.linen as nn\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "class FourierTransformLayer(nn.Module):\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    return jax.vmap(jnp.fft.fftn)(x).real\n",
        "\n",
        "class FeedForwardLayer(nn.Module):\n",
        "  d_ff: int\n",
        "  dropout_rate: float\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x, deterministic):\n",
        "    x = nn.Dense(self.d_ff,\n",
        "                 kernel_init=nn.initializers.normal(2e-2),\n",
        "                 bias_init=nn.initializers.normal(2e-2),\n",
        "                 name=\"intermediate\")(x)\n",
        "    x = jax.nn.gelu(x)  # Use jax.nn.gelu for more compatibility\n",
        "    x = nn.Dense(x.shape[-1],\n",
        "                 kernel_init=nn.initializers.normal(2e-2),\n",
        "                 name=\"output\")(x)\n",
        "    return nn.Dropout(self.dropout_rate)(x, deterministic)\n",
        "\n",
        "class FNetEncoderBlock(nn.Module):\n",
        "  fourier_layer: FourierTransformLayer\n",
        "  ff_layer: FeedForwardLayer\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x, deterministic):\n",
        "    mixing_output = self.fourier_layer(x)\n",
        "    x = nn.LayerNorm(1e-12, name=\"mixing_layer_norm\")(x + mixing_output)\n",
        "    feed_forward_output = self.ff_layer(x, deterministic)\n",
        "    return nn.LayerNorm(1e-12, name=\"output_layer_norm\")(x + feed_forward_output)\n",
        "\n",
        "class FNetEncoder(nn.Module):\n",
        "    num_layers: int\n",
        "    d_model: int\n",
        "    d_ff: int\n",
        "    dropout_rate: float\n",
        "\n",
        "    def setup(self):\n",
        "        encoder_blocks = []\n",
        "        for layer in range(self.num_layers):\n",
        "            encoder_blocks.append(\n",
        "                FNetEncoderBlock(\n",
        "                    FourierTransformLayer(),\n",
        "                    FeedForwardLayer(self.d_ff, self.dropout_rate),\n",
        "                    name=f'encoder_{layer}'\n",
        "                ))\n",
        "        # Make encoder_blocks public (use with caution)\n",
        "        self.encoder_blocks = encoder_blocks\n",
        "        self.pooler = nn.Dense(\n",
        "            self.d_model,\n",
        "            kernel_init=nn.initializers.normal(2e-2),\n",
        "            name='pooler')\n",
        "\n",
        "    def __call__(self, x, deterministic):\n",
        "        for encoder_block in self.encoder_blocks:\n",
        "            x = encoder_block(x, deterministic)\n",
        "        pooled_output = self.pooler(x[:, 0])\n",
        "        pooled_output = jnp.tanh(pooled_output)\n",
        "        return x, pooled_output\n",
        "# Test function\n",
        "def test_fnet_encoder(encoder, test_data, deterministic=True):\n",
        "  outputs, pooled_outputs = encoder(test_data, deterministic)\n",
        "\n",
        "  # Check output shapes\n",
        "  assert outputs.shape == (batch_size, sequence_length, d_model)\n",
        "  assert pooled_outputs.shape == (batch_size, d_model)\n",
        "\n",
        "  # Evaluate performance (example: calculate accuracy)\n",
        "  # ...\n",
        "\n",
        "  return outputs, pooled_outputs\n",
        "\n",
        "# Example usage\n",
        "batch_size = 16\n",
        "sequence_length = 32\n",
        "d_model = 512\n",
        "d_ff = 1024\n",
        "dropout_rate = 0.1\n",
        "num_layers = 6\n",
        "\n",
        "encoder = FNetEncoder(num_layers=num_layers, d_model=d_model, d_ff=d_ff, dropout_rate=dropout_rate)\n",
        "\n",
        "# Generate or load test data\n",
        "test_data = jax.random.normal(jax.random.PRNGKey(42), (batch_size, sequence_length, d_model))\n",
        "\n",
        "# Run the test\n",
        "outputs, pooled_outputs = test_fnet_encoder(encoder, test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "_MTDDoNPN06z",
        "outputId": "817d3887-ac4f-40d0-a14e-8ff0043afe18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "\"FNetEncoder\" object has no attribute \"encoder_blocks\". If \"encoder_blocks\" is defined in '.setup()', remember these fields are only accessible from inside 'init' or 'apply'.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-87f0df1c6bcb>\u001b[0m in \u001b[0;36m<cell line: 92>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m# Run the test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_fnet_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-87f0df1c6bcb>\u001b[0m in \u001b[0;36mtest_fnet_encoder\u001b[0;34m(encoder, test_data, deterministic)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Test function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_fnet_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;31m# Check output shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36mwrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_wrapped_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36m_call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_use_named_call\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_derive_profiling_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m           \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-87f0df1c6bcb>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, deterministic)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mencoder_block\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1324\u001b[0m           \u001b[0;34m\"are only accessible from inside 'init' or 'apply'.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: \"FNetEncoder\" object has no attribute \"encoder_blocks\". If \"encoder_blocks\" is defined in '.setup()', remember these fields are only accessible from inside 'init' or 'apply'."
          ]
        }
      ]
    }
  ]
}